```{r adapt_load, echo = FALSE, message=FALSE, warning=FALSE}
library(caret)
library(pROC)
library(kernlab)
library(nlme)
library(QSARdata)

theme_set(theme_bw())
library(knitr)
opts_chunk$set(digits = 3, tidy = FALSE)

```
# Adaptive Resampling

Models can benefit significantly from tuning but the optimal values are rarely known beforehand. `train` can be used to define a grid of possible points and resampling can be used to generate good estimates of performance for each tuning parameter combination. However, in the nominal resampling process, all the tuning parameter combinations are computed for all the resamples before a choice is made about which parameters are good and which are poor.

[`caret`](http://cran.r-project.org/web/packages/caret/index.html) contains the ability to adaptively resample the tuning parameter grid in a way that concentrates on values that are the in the neighborhood of the optimal settings. See [this paper](http://arxiv.org/abs/1405.6974) for the details.

To illustrate, we will use the Sonar data from one of the [previous pages](https://topepo.github.io/caret/model-training-and-tuning.html#tune). 

```{r adapt_data, eval = FALSE}
library(mlbench)
data(Sonar)
library(caret)
set.seed(998)
inTraining <- createDataPartition(Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTraining,]
testing  <- Sonar[-inTraining,]
```

We will tune a support vector machine model using the same tuning strategy as before but with [random search](https://topepo.github.io/caret/random-hyperparameter-search.html): 

```{r adapt_full_mod, cache = TRUE}
svmControl <- trainControl(method = "repeatedcv",
                           number = 10, repeats = 10,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary,
                           search = "random")
set.seed(825)
svmFit <- train(Class ~ ., data = training,
                method = "svmRadial", 
                trControl = svmControl, 
                preProc = c("center", "scale"),
                metric = "ROC",
                tuneLength = 15)
```

Using this method, the optimal tuning parameters were a RBF kernel parameter of `r I(round(svmFit$bestTune$sigma, 4))` and a cost value of `r I(svmFit$bestTune$C)`. To use the adaptive procedure, the `trainControl` option needs some additional arguments:

 - `min` is the minimum number of resamples that will be used for each tuning parameter. The default value is 5 and increasing it will decrease the speed-up generated by adaptive resampling but should also increase the likelihood of finding a good model.
 - `alpha` is a confidence level that is used to remove parameter settings. To date, this value has not shown much of an effect.
 - `method` is either `"gls"` for a linear model or `"BT"` for a Bradley-Terry model. The latter may be more useful when you expect the model to do very well (e.g. an area under the ROC curve near 1) or when there are a large number of tuning parameter settings.
 - `complete` is a logical value that specifies whether `train` should generate the full resampling set if it finds an optimal solution before the end of resampling. If you want to know the optimal parameter settings and don't care much for the estimated performance value, a value of `FALSE` would be appropriate here.

The new code is below. Recall that setting the random number seed just prior to the model fit will ensure the same resamples as well as the same random grid.

```{r adapt_mod, cache = TRUE}
adaptControl <- trainControl(method = "adaptive_cv",
                             number = 10, repeats = 10,
                             adaptive = list(min = 5, alpha = 0.05, 
                                             method = "gls", complete = TRUE),
                             classProbs = TRUE,
                             summaryFunction = twoClassSummary,
                             search = "random")

set.seed(825)
svmAdapt <- train(Class ~ ., data = training,
                  method = "svmRadial", 
                  trControl = adaptControl, 
                  preProc = c("center", "scale"),
                  metric = "ROC",
                  tuneLength = 15)
```

The search finalized the tuning parameters on the `r max(svmAdapt$results$.B[-which.max(svmAdapt$results$.B)])`th iteration of resampling and was `r I(round(svmFit$times$everything[3]/svmAdapt$times$everything[3], 1))`-fold faster than the original analysis. Here, the optimal tuning parameters were a RBF kernel parameter of `r I(round(svmAdapt$bestTune$sigma, 4))` and a cost value of `r I(svmAdapt$bestTune$C)`. These are close to the previous settings and result in a difference in the area under the ROC curve of `r round(getTrainPerf(svmFit)[1,1] - getTrainPerf(svmAdapt)[1,1], 3)` and the adaptive approach used `r length(svmFit$control$index)*nrow(svmFit$results) - sum(svmAdapt$results$.B)` fewer models.  

Remember that this methodology is experimental, so please send any [questions or bug reports](https://github.com/topepo/caret/issues) to the package maintainer.
