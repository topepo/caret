<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>The caret Package</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Documentation for the <code>caret</code> package">
  <meta name="generator" content="bookdown 0.1 and GitBook 2.6.7">

  <meta property="og:title" content="The caret Package" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Documentation for the <code>caret</code> package" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="The caret Package" />
  
  <meta name="twitter:description" content="Documentation for the <code>caret</code> package" />
  

<meta name="author" content="Max Kuhn">

<meta name="date" content="2016-09-03">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="random-hyperparameter-search.html">
<link rel="next" href="using-your-own-model-in-train.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-0.6/htmlwidgets.js"></script>
<script src="libs/datatables-binding-0.1/datatables.js"></script>
<script src="libs/datatables-1.10.7/jquery.dataTables.min.js"></script>
<link href="libs/datatables-bootstrap-1.10.7/dataTables.bootstrap.css" rel="stylesheet" />
<link href="libs/datatables-bootstrap-1.10.7/dataTables.extra.css" rel="stylesheet" />
<script src="libs/datatables-bootstrap-1.10.7/dataTables.bootstrap.min.js"></script>
<script src="libs/d3-3.5.2/d3.min.js"></script>
<script src="libs/forceNetwork-binding-0.2.11/forceNetwork.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="visualizations.html"><a href="visualizations.html"><i class="fa fa-check"></i><b>2</b> Visualizations</a></li>
<li class="chapter" data-level="3" data-path="pre-processing.html"><a href="pre-processing.html"><i class="fa fa-check"></i><b>3</b> Pre-Processing</a><ul>
<li class="chapter" data-level="3.1" data-path="pre-processing.html"><a href="pre-processing.html#creating-dummy-variables"><i class="fa fa-check"></i><b>3.1</b> Creating Dummy Variables</a></li>
<li class="chapter" data-level="3.2" data-path="pre-processing.html"><a href="pre-processing.html#zero--and-near-zero-variance-predictors"><i class="fa fa-check"></i><b>3.2</b> Zero- and Near Zero-Variance Predictors</a></li>
<li class="chapter" data-level="3.3" data-path="pre-processing.html"><a href="pre-processing.html#identifying-correlated-predictors"><i class="fa fa-check"></i><b>3.3</b> Identifying Correlated Predictors</a></li>
<li class="chapter" data-level="3.4" data-path="pre-processing.html"><a href="pre-processing.html#linear-dependencies"><i class="fa fa-check"></i><b>3.4</b> Linear Dependencies</a></li>
<li class="chapter" data-level="3.5" data-path="pre-processing.html"><a href="pre-processing.html#the-preprocess-function"><i class="fa fa-check"></i><b>3.5</b> The <code>preProcess</code> Function</a></li>
<li class="chapter" data-level="3.6" data-path="pre-processing.html"><a href="pre-processing.html#centering-and-scaling"><i class="fa fa-check"></i><b>3.6</b> Centering and Scaling</a></li>
<li class="chapter" data-level="3.7" data-path="pre-processing.html"><a href="pre-processing.html#imputation"><i class="fa fa-check"></i><b>3.7</b> Imputation</a></li>
<li class="chapter" data-level="3.8" data-path="pre-processing.html"><a href="pre-processing.html#transforming-predictors"><i class="fa fa-check"></i><b>3.8</b> Transforming Predictors</a></li>
<li class="chapter" data-level="3.9" data-path="pre-processing.html"><a href="pre-processing.html#putting-it-all-together"><i class="fa fa-check"></i><b>3.9</b> Putting It All Together</a></li>
<li class="chapter" data-level="3.10" data-path="pre-processing.html"><a href="pre-processing.html#class-distance-calculations"><i class="fa fa-check"></i><b>3.10</b> Class Distance Calculations</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-splitting.html"><a href="data-splitting.html"><i class="fa fa-check"></i><b>4</b> Data Splitting</a><ul>
<li class="chapter" data-level="4.1" data-path="data-splitting.html"><a href="data-splitting.html#simple-splitting-based-on-the-outcome"><i class="fa fa-check"></i><b>4.1</b> Simple Splitting Based on the Outcome</a></li>
<li class="chapter" data-level="4.2" data-path="data-splitting.html"><a href="data-splitting.html#splitting-based-on-the-predictors"><i class="fa fa-check"></i><b>4.2</b> Splitting Based on the Predictors</a></li>
<li class="chapter" data-level="4.3" data-path="data-splitting.html"><a href="data-splitting.html#data-splitting-for-time-series"><i class="fa fa-check"></i><b>4.3</b> Data Splitting for Time Series</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html"><i class="fa fa-check"></i><b>5</b> Model Training and Tuning</a><ul>
<li class="chapter" data-level="5.1" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#model-training-and-parameter-tuning"><i class="fa fa-check"></i><b>5.1</b> Model Training and Parameter Tuning</a></li>
<li class="chapter" data-level="5.2" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#an-example"><i class="fa fa-check"></i><b>5.2</b> An Example</a></li>
<li class="chapter" data-level="5.3" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#basic-parameter-tuning"><i class="fa fa-check"></i><b>5.3</b> Basic Parameter Tuning</a></li>
<li class="chapter" data-level="5.4" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#notes-on-reproducibility"><i class="fa fa-check"></i><b>5.4</b> Notes on Reproducibility</a></li>
<li class="chapter" data-level="5.5" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#customizing-the-tuning-process"><i class="fa fa-check"></i><b>5.5</b> Customizing the Tuning Process</a><ul>
<li class="chapter" data-level="5.5.1" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#pre-processing-options"><i class="fa fa-check"></i><b>5.5.1</b> Pre-Processing Options</a></li>
<li class="chapter" data-level="5.5.2" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#alternate-tuning-grids"><i class="fa fa-check"></i><b>5.5.2</b> Alternate Tuning Grids</a></li>
<li class="chapter" data-level="5.5.3" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#plotting-the-resampling-profile"><i class="fa fa-check"></i><b>5.5.3</b> Plotting the Resampling Profile</a></li>
<li class="chapter" data-level="5.5.4" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#the-traincontrol-function"><i class="fa fa-check"></i><b>5.5.4</b> The <code>trainControl</code> Function</a></li>
<li class="chapter" data-level="5.5.5" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#alternate-performance-metrics"><i class="fa fa-check"></i><b>5.5.5</b> Alternate Performance Metrics</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#choosing-the-final-model"><i class="fa fa-check"></i><b>5.6</b> Choosing the Final Model</a></li>
<li class="chapter" data-level="5.7" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#extracting-predictions-and-class-probabilities"><i class="fa fa-check"></i><b>5.7</b> Extracting Predictions and Class Probabilities</a></li>
<li class="chapter" data-level="5.8" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#exploring-and-comparing-resampling-distributions"><i class="fa fa-check"></i><b>5.8</b> Exploring and Comparing Resampling Distributions</a><ul>
<li class="chapter" data-level="5.8.1" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#within-model"><i class="fa fa-check"></i><b>5.8.1</b> Within-Model</a></li>
<li class="chapter" data-level="5.8.2" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#between-models"><i class="fa fa-check"></i><b>5.8.2</b> Between-Models</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#fitting-models-without-parameter-tuning"><i class="fa fa-check"></i><b>5.9</b> Fitting Models Without Parameter Tuning</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="available-models.html"><a href="available-models.html"><i class="fa fa-check"></i><b>6</b> Available Models</a></li>
<li class="chapter" data-level="7" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html"><i class="fa fa-check"></i><b>7</b> <code>train</code> Models By Tag</a><ul>
<li class="chapter" data-level="7.0.1" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#accepts-case-weights"><i class="fa fa-check"></i><b>7.0.1</b> Accepts Case Weights</a></li>
<li class="chapter" data-level="7.0.2" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#bagging"><i class="fa fa-check"></i><b>7.0.2</b> Bagging</a></li>
<li class="chapter" data-level="7.0.3" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#bayesian-model"><i class="fa fa-check"></i><b>7.0.3</b> Bayesian Model</a></li>
<li class="chapter" data-level="7.0.4" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#binary-predictors-only"><i class="fa fa-check"></i><b>7.0.4</b> Binary Predictors Only</a></li>
<li class="chapter" data-level="7.0.5" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#boosting"><i class="fa fa-check"></i><b>7.0.5</b> Boosting</a></li>
<li class="chapter" data-level="7.0.6" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#categorical-predictors-only"><i class="fa fa-check"></i><b>7.0.6</b> Categorical Predictors Only</a></li>
<li class="chapter" data-level="7.0.7" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#cost-sensitive-learning"><i class="fa fa-check"></i><b>7.0.7</b> Cost Sensitive Learning</a></li>
<li class="chapter" data-level="7.0.8" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#discriminant-analysis"><i class="fa fa-check"></i><b>7.0.8</b> Discriminant Analysis</a></li>
<li class="chapter" data-level="7.0.9" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#distance-weighted-discrimination"><i class="fa fa-check"></i><b>7.0.9</b> Distance Weighted Discrimination</a></li>
<li class="chapter" data-level="7.0.10" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#ensemble-model"><i class="fa fa-check"></i><b>7.0.10</b> Ensemble Model</a></li>
<li class="chapter" data-level="7.0.11" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#feature-extraction"><i class="fa fa-check"></i><b>7.0.11</b> Feature Extraction</a></li>
<li class="chapter" data-level="7.0.12" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#feature-selection-wrapper"><i class="fa fa-check"></i><b>7.0.12</b> Feature Selection Wrapper</a></li>
<li class="chapter" data-level="7.0.13" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#gaussian-process"><i class="fa fa-check"></i><b>7.0.13</b> Gaussian Process</a></li>
<li class="chapter" data-level="7.0.14" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#generalized-additive-model"><i class="fa fa-check"></i><b>7.0.14</b> Generalized Additive Model</a></li>
<li class="chapter" data-level="7.0.15" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#generalized-linear-model"><i class="fa fa-check"></i><b>7.0.15</b> Generalized Linear Model</a></li>
<li class="chapter" data-level="7.0.16" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#handle-missing-predictor-data"><i class="fa fa-check"></i><b>7.0.16</b> Handle Missing Predictor Data</a></li>
<li class="chapter" data-level="7.0.17" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#implicit-feature-selection"><i class="fa fa-check"></i><b>7.0.17</b> Implicit Feature Selection</a></li>
<li class="chapter" data-level="7.0.18" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#kernel-method"><i class="fa fa-check"></i><b>7.0.18</b> Kernel Method</a></li>
<li class="chapter" data-level="7.0.19" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#l1-regularization"><i class="fa fa-check"></i><b>7.0.19</b> L1 Regularization</a></li>
<li class="chapter" data-level="7.0.20" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#l2-regularization"><i class="fa fa-check"></i><b>7.0.20</b> L2 Regularization</a></li>
<li class="chapter" data-level="7.0.21" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#linear-classifier"><i class="fa fa-check"></i><b>7.0.21</b> Linear Classifier</a></li>
<li class="chapter" data-level="7.0.22" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#linear-regression"><i class="fa fa-check"></i><b>7.0.22</b> Linear Regression</a></li>
<li class="chapter" data-level="7.0.23" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#logic-regression"><i class="fa fa-check"></i><b>7.0.23</b> Logic Regression</a></li>
<li class="chapter" data-level="7.0.24" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#logistic-regression"><i class="fa fa-check"></i><b>7.0.24</b> Logistic Regression</a></li>
<li class="chapter" data-level="7.0.25" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#mixture-model"><i class="fa fa-check"></i><b>7.0.25</b> Mixture Model</a></li>
<li class="chapter" data-level="7.0.26" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#model-tree"><i class="fa fa-check"></i><b>7.0.26</b> Model Tree</a></li>
<li class="chapter" data-level="7.0.27" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#multivariate-adaptive-regression-splines"><i class="fa fa-check"></i><b>7.0.27</b> Multivariate Adaptive Regression Splines</a></li>
<li class="chapter" data-level="7.0.28" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#neural-network"><i class="fa fa-check"></i><b>7.0.28</b> Neural Network</a></li>
<li class="chapter" data-level="7.0.29" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#oblique-tree"><i class="fa fa-check"></i><b>7.0.29</b> Oblique Tree</a></li>
<li class="chapter" data-level="7.0.30" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#ordinal-outcomes"><i class="fa fa-check"></i><b>7.0.30</b> Ordinal Outcomes</a></li>
<li class="chapter" data-level="7.0.31" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#partial-least-squares"><i class="fa fa-check"></i><b>7.0.31</b> Partial Least Squares</a></li>
<li class="chapter" data-level="7.0.32" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#polynomial-model"><i class="fa fa-check"></i><b>7.0.32</b> Polynomial Model</a></li>
<li class="chapter" data-level="7.0.33" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#prototype-models"><i class="fa fa-check"></i><b>7.0.33</b> Prototype Models</a></li>
<li class="chapter" data-level="7.0.34" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#quantile-regression"><i class="fa fa-check"></i><b>7.0.34</b> Quantile Regression</a></li>
<li class="chapter" data-level="7.0.35" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#radial-basis-function"><i class="fa fa-check"></i><b>7.0.35</b> Radial Basis Function</a></li>
<li class="chapter" data-level="7.0.36" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#random-forest"><i class="fa fa-check"></i><b>7.0.36</b> Random Forest</a></li>
<li class="chapter" data-level="7.0.37" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#regularization"><i class="fa fa-check"></i><b>7.0.37</b> Regularization</a></li>
<li class="chapter" data-level="7.0.38" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#relevance-vector-machines"><i class="fa fa-check"></i><b>7.0.38</b> Relevance Vector Machines</a></li>
<li class="chapter" data-level="7.0.39" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#ridge-regression"><i class="fa fa-check"></i><b>7.0.39</b> Ridge Regression</a></li>
<li class="chapter" data-level="7.0.40" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#robust-methods"><i class="fa fa-check"></i><b>7.0.40</b> Robust Methods</a></li>
<li class="chapter" data-level="7.0.41" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#robust-model"><i class="fa fa-check"></i><b>7.0.41</b> Robust Model</a></li>
<li class="chapter" data-level="7.0.42" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#roc-curves"><i class="fa fa-check"></i><b>7.0.42</b> ROC Curves</a></li>
<li class="chapter" data-level="7.0.43" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#rule-based-model"><i class="fa fa-check"></i><b>7.0.43</b> Rule-Based Model</a></li>
<li class="chapter" data-level="7.0.44" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#self-organising-maps"><i class="fa fa-check"></i><b>7.0.44</b> Self-Organising Maps</a></li>
<li class="chapter" data-level="7.0.45" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#string-kernel"><i class="fa fa-check"></i><b>7.0.45</b> String Kernel</a></li>
<li class="chapter" data-level="7.0.46" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#support-vector-machines"><i class="fa fa-check"></i><b>7.0.46</b> Support Vector Machines</a></li>
<li class="chapter" data-level="7.0.47" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#text-mining"><i class="fa fa-check"></i><b>7.0.47</b> Text Mining</a></li>
<li class="chapter" data-level="7.0.48" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#tree-based-model"><i class="fa fa-check"></i><b>7.0.48</b> Tree-Based Model</a></li>
<li class="chapter" data-level="7.0.49" data-path="train-models-by-tag.html"><a href="train-models-by-tag.html#two-class-only"><i class="fa fa-check"></i><b>7.0.49</b> Two Class Only</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="models-clustered-by-tag-similarity.html"><a href="models-clustered-by-tag-similarity.html"><i class="fa fa-check"></i><b>8</b> Models Clustered by Tag Similarity</a></li>
<li class="chapter" data-level="9" data-path="parallel-processing.html"><a href="parallel-processing.html"><i class="fa fa-check"></i><b>9</b> Parallel Processing</a></li>
<li class="chapter" data-level="10" data-path="random-hyperparameter-search.html"><a href="random-hyperparameter-search.html"><i class="fa fa-check"></i><b>10</b> Random Hyperparameter Search</a></li>
<li class="chapter" data-level="11" data-path="subsampling-for-class-imbalances.html"><a href="subsampling-for-class-imbalances.html"><i class="fa fa-check"></i><b>11</b> Subsampling For Class Imbalances</a><ul>
<li class="chapter" data-level="11.1" data-path="subsampling-for-class-imbalances.html"><a href="subsampling-for-class-imbalances.html#subsampling-techniques"><i class="fa fa-check"></i><b>11.1</b> Subsampling Techniques</a></li>
<li class="chapter" data-level="11.2" data-path="subsampling-for-class-imbalances.html"><a href="subsampling-for-class-imbalances.html#subsampling-during-resampling"><i class="fa fa-check"></i><b>11.2</b> Subsampling During Resampling</a></li>
<li class="chapter" data-level="11.3" data-path="subsampling-for-class-imbalances.html"><a href="subsampling-for-class-imbalances.html#complications"><i class="fa fa-check"></i><b>11.3</b> Complications</a></li>
<li class="chapter" data-level="11.4" data-path="subsampling-for-class-imbalances.html"><a href="subsampling-for-class-imbalances.html#using-custom-subsampling-techniques"><i class="fa fa-check"></i><b>11.4</b> Using Custom Subsampling Techniques</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html"><i class="fa fa-check"></i><b>12</b> Using Your Own Model in <code>train</code></a><ul>
<li class="chapter" data-level="12.1" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#introduction-1"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#illustrative-example-1-svms-with-laplacian-kernels"><i class="fa fa-check"></i><b>12.2</b> Illustrative Example 1: SVMs with Laplacian Kernels</a></li>
<li class="chapter" data-level="12.3" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#model-components"><i class="fa fa-check"></i><b>12.3</b> Model Components</a><ul>
<li class="chapter" data-level="12.3.1" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#the-parameters-element"><i class="fa fa-check"></i><b>12.3.1</b> The parameters Element</a></li>
<li class="chapter" data-level="12.3.2" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#the-grid-element"><i class="fa fa-check"></i><b>12.3.2</b> The <code>grid</code> Element</a></li>
<li class="chapter" data-level="12.3.3" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#the-fit-element"><i class="fa fa-check"></i><b>12.3.3</b> The <code>fit</code> Element</a></li>
<li class="chapter" data-level="12.3.4" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#the-predict-element"><i class="fa fa-check"></i><b>12.3.4</b> The <code>predict</code> Element</a></li>
<li class="chapter" data-level="12.3.5" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#the-prob-element"><i class="fa fa-check"></i><b>12.3.5</b> The <code>prob</code> Element</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#the-sort-element"><i class="fa fa-check"></i><b>12.4</b> The sort Element</a><ul>
<li class="chapter" data-level="12.4.1" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#the-levels-element"><i class="fa fa-check"></i><b>12.4.1</b> The <code>levels</code> Element</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#illustrative-example-2-something-more-complicated---logitboost"><i class="fa fa-check"></i><b>12.5</b> Illustrative Example 2: Something More Complicated - <code>LogitBoost</code></a><ul>
<li class="chapter" data-level="12.5.1" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#the-loop-element"><i class="fa fa-check"></i><b>12.5.1</b> The loop Element</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#illustrative-example-3-nonstandard-formulas"><i class="fa fa-check"></i><b>12.6</b> Illustrative Example 3: Nonstandard Formulas</a></li>
<li class="chapter" data-level="12.7" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#illustrative-example-4-pls-feature-extraction-pre-processing"><i class="fa fa-check"></i><b>12.7</b> Illustrative Example 4: PLS Feature Extraction Pre-Processing</a></li>
<li class="chapter" data-level="12.8" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#illustrative-example-5-optimizing-probability-thresholds-for-class-imbalances"><i class="fa fa-check"></i><b>12.8</b> Illustrative Example 5: Optimizing probability thresholds for class imbalances</a></li>
<li class="chapter" data-level="12.9" data-path="using-your-own-model-in-train.html"><a href="using-your-own-model-in-train.html#illustrative-example-6-offsets-in-generalized-linear-models"><i class="fa fa-check"></i><b>12.9</b> Illustrative Example 6: Offsets in Generalized Linear Models</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="adaptive-resampling.html"><a href="adaptive-resampling.html"><i class="fa fa-check"></i><b>13</b> Adaptive Resampling</a></li>
<li class="chapter" data-level="14" data-path="variable-importance.html"><a href="variable-importance.html"><i class="fa fa-check"></i><b>14</b> Variable Importance</a><ul>
<li class="chapter" data-level="14.1" data-path="variable-importance.html"><a href="variable-importance.html#model-specific-metrics"><i class="fa fa-check"></i><b>14.1</b> Model Specific Metrics</a></li>
<li class="chapter" data-level="14.2" data-path="variable-importance.html"><a href="variable-importance.html#model-independent-metrics"><i class="fa fa-check"></i><b>14.2</b> Model Independent Metrics</a></li>
<li class="chapter" data-level="14.3" data-path="variable-importance.html"><a href="variable-importance.html#an-example-1"><i class="fa fa-check"></i><b>14.3</b> An Example</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="miscellaneous-model-functions.html"><a href="miscellaneous-model-functions.html"><i class="fa fa-check"></i><b>15</b> Miscellaneous Model Functions</a><ul>
<li class="chapter" data-level="15.1" data-path="miscellaneous-model-functions.html"><a href="miscellaneous-model-functions.html#yet-another-k-nearest-neighbor-function"><i class="fa fa-check"></i><b>15.1</b> Yet Another <em>k</em>-Nearest Neighbor Function</a></li>
<li class="chapter" data-level="15.2" data-path="miscellaneous-model-functions.html"><a href="miscellaneous-model-functions.html#partial-least-squares-discriminant-analysis"><i class="fa fa-check"></i><b>15.2</b> Partial Least Squares Discriminant Analysis</a></li>
<li class="chapter" data-level="15.3" data-path="miscellaneous-model-functions.html"><a href="miscellaneous-model-functions.html#bagged-mars-and-fda"><i class="fa fa-check"></i><b>15.3</b> Bagged MARS and FDA</a></li>
<li class="chapter" data-level="15.4" data-path="miscellaneous-model-functions.html"><a href="miscellaneous-model-functions.html#bagging-1"><i class="fa fa-check"></i><b>15.4</b> Bagging</a><ul>
<li class="chapter" data-level="15.4.1" data-path="miscellaneous-model-functions.html"><a href="miscellaneous-model-functions.html#the-fit-function"><i class="fa fa-check"></i><b>15.4.1</b> The <code>fit</code> Function</a></li>
<li class="chapter" data-level="15.4.2" data-path="miscellaneous-model-functions.html"><a href="miscellaneous-model-functions.html#the-pred-function"><i class="fa fa-check"></i><b>15.4.2</b> The <code>pred</code> Function</a></li>
<li class="chapter" data-level="15.4.3" data-path="miscellaneous-model-functions.html"><a href="miscellaneous-model-functions.html#the-aggregate-function"><i class="fa fa-check"></i><b>15.4.3</b> The <code>aggregate</code> Function</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="miscellaneous-model-functions.html"><a href="miscellaneous-model-functions.html#model-averaged-neural-networks"><i class="fa fa-check"></i><b>15.5</b> Model Averaged Neural Networks</a></li>
<li class="chapter" data-level="15.6" data-path="miscellaneous-model-functions.html"><a href="miscellaneous-model-functions.html#neural-networks-with-a-principal-component-step"><i class="fa fa-check"></i><b>15.6</b> Neural Networks with a Principal Component Step</a></li>
<li class="chapter" data-level="15.7" data-path="miscellaneous-model-functions.html"><a href="miscellaneous-model-functions.html#independent-component-regression"><i class="fa fa-check"></i><b>15.7</b> Independent Component Regression</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="measuring-performance.html"><a href="measuring-performance.html"><i class="fa fa-check"></i><b>16</b> Measuring Performance</a><ul>
<li class="chapter" data-level="16.1" data-path="measuring-performance.html"><a href="measuring-performance.html#measures-for-regression"><i class="fa fa-check"></i><b>16.1</b> Measures for Regression</a></li>
<li class="chapter" data-level="16.2" data-path="measuring-performance.html"><a href="measuring-performance.html#measures-for-predicted-classes"><i class="fa fa-check"></i><b>16.2</b> Measures for Predicted Classes</a></li>
<li class="chapter" data-level="16.3" data-path="measuring-performance.html"><a href="measuring-performance.html#measures-for-class-probabilities"><i class="fa fa-check"></i><b>16.3</b> Measures for Class Probabilities</a></li>
<li class="chapter" data-level="16.4" data-path="measuring-performance.html"><a href="measuring-performance.html#lift-curves"><i class="fa fa-check"></i><b>16.4</b> Lift Curves</a></li>
<li class="chapter" data-level="16.5" data-path="measuring-performance.html"><a href="measuring-performance.html#calibration-curves"><i class="fa fa-check"></i><b>16.5</b> Calibration Curves</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="feature-selection-overview.html"><a href="feature-selection-overview.html"><i class="fa fa-check"></i><b>17</b> Feature Selection Overview</a><ul>
<li class="chapter" data-level="17.1" data-path="feature-selection-overview.html"><a href="feature-selection-overview.html#models-with-built-in-feature-selection"><i class="fa fa-check"></i><b>17.1</b> Models with Built-In Feature Selection</a></li>
<li class="chapter" data-level="17.2" data-path="feature-selection-overview.html"><a href="feature-selection-overview.html#feature-selection-methods"><i class="fa fa-check"></i><b>17.2</b> Feature Selection Methods</a></li>
<li class="chapter" data-level="17.3" data-path="feature-selection-overview.html"><a href="feature-selection-overview.html#external-validation"><i class="fa fa-check"></i><b>17.3</b> External Validation</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="recursive-feature-elimination.html"><a href="recursive-feature-elimination.html"><i class="fa fa-check"></i><b>18</b> Recursive Feature Elimination</a><ul>
<li class="chapter" data-level="18.1" data-path="recursive-feature-elimination.html"><a href="recursive-feature-elimination.html#backwards-selection"><i class="fa fa-check"></i><b>18.1</b> Backwards Selection</a></li>
<li class="chapter" data-level="18.2" data-path="recursive-feature-elimination.html"><a href="recursive-feature-elimination.html#resampling-and-external-validation"><i class="fa fa-check"></i><b>18.2</b> Resampling and External Validation</a></li>
<li class="chapter" data-level="18.3" data-path="recursive-feature-elimination.html"><a href="recursive-feature-elimination.html#recursive-feature-elimination-via-caret"><i class="fa fa-check"></i><b>18.3</b> Recursive Feature Elimination via <a href="http://cran.r-project.org/web/packages/caret/index.html"><code>caret</code></a></a></li>
<li class="chapter" data-level="18.4" data-path="recursive-feature-elimination.html"><a href="recursive-feature-elimination.html#an-example-2"><i class="fa fa-check"></i><b>18.4</b> An Example</a></li>
<li class="chapter" data-level="18.5" data-path="recursive-feature-elimination.html"><a href="recursive-feature-elimination.html#helper-functions"><i class="fa fa-check"></i><b>18.5</b> Helper Functions</a><ul>
<li class="chapter" data-level="18.5.1" data-path="recursive-feature-elimination.html"><a href="recursive-feature-elimination.html#the-summary-function"><i class="fa fa-check"></i><b>18.5.1</b> The <code>summary</code> Function</a></li>
<li class="chapter" data-level="18.5.2" data-path="recursive-feature-elimination.html"><a href="recursive-feature-elimination.html#the-fit-function-1"><i class="fa fa-check"></i><b>18.5.2</b> The <code>fit</code> Function</a></li>
<li class="chapter" data-level="18.5.3" data-path="recursive-feature-elimination.html"><a href="recursive-feature-elimination.html#the-pred-function-1"><i class="fa fa-check"></i><b>18.5.3</b> The <code>pred</code> Function</a></li>
<li class="chapter" data-level="18.5.4" data-path="recursive-feature-elimination.html"><a href="recursive-feature-elimination.html#the-rank-function"><i class="fa fa-check"></i><b>18.5.4</b> The <code>rank</code> Function</a></li>
<li class="chapter" data-level="18.5.5" data-path="recursive-feature-elimination.html"><a href="recursive-feature-elimination.html#the-selectsize-function"><i class="fa fa-check"></i><b>18.5.5</b> The <code>selectSize</code> Function</a></li>
<li class="chapter" data-level="18.5.6" data-path="recursive-feature-elimination.html"><a href="recursive-feature-elimination.html#the-selectvar-function"><i class="fa fa-check"></i><b>18.5.6</b> The <code>selectVar</code> Function</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="recursive-feature-elimination.html"><a href="recursive-feature-elimination.html#the-example"><i class="fa fa-check"></i><b>18.6</b> The Example</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="feature-selection-using-univariate-filters.html"><a href="feature-selection-using-univariate-filters.html"><i class="fa fa-check"></i><b>19</b> Feature Selection using Univariate Filters</a><ul>
<li class="chapter" data-level="19.1" data-path="feature-selection-using-univariate-filters.html"><a href="feature-selection-using-univariate-filters.html#univariate-filters"><i class="fa fa-check"></i><b>19.1</b> Univariate Filters</a></li>
<li class="chapter" data-level="19.2" data-path="feature-selection-using-univariate-filters.html"><a href="feature-selection-using-univariate-filters.html#basic-syntax"><i class="fa fa-check"></i><b>19.2</b> Basic Syntax</a><ul>
<li class="chapter" data-level="19.2.1" data-path="feature-selection-using-univariate-filters.html"><a href="feature-selection-using-univariate-filters.html#the-score-function"><i class="fa fa-check"></i><b>19.2.1</b> The <code>score</code> Function</a></li>
<li class="chapter" data-level="19.2.2" data-path="feature-selection-using-univariate-filters.html"><a href="feature-selection-using-univariate-filters.html#the-filter-function"><i class="fa fa-check"></i><b>19.2.2</b> The <code>filter</code> Function</a></li>
<li class="chapter" data-level="19.2.3" data-path="feature-selection-using-univariate-filters.html"><a href="feature-selection-using-univariate-filters.html#the-fit-function-2"><i class="fa fa-check"></i><b>19.2.3</b> The <code>fit</code> Function</a></li>
<li class="chapter" data-level="19.2.4" data-path="feature-selection-using-univariate-filters.html"><a href="feature-selection-using-univariate-filters.html#the-summary-and-pred-functions"><i class="fa fa-check"></i><b>19.2.4</b> The <code>summary</code> and <code>pred</code> Functions</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="feature-selection-using-univariate-filters.html"><a href="feature-selection-using-univariate-filters.html#the-example-1"><i class="fa fa-check"></i><b>19.3</b> The Example</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html"><i class="fa fa-check"></i><b>20</b> Feature Selection using Genetic Algorithms</a><ul>
<li class="chapter" data-level="20.1" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#genetic-algorithms"><i class="fa fa-check"></i><b>20.1</b> Genetic Algorithms</a></li>
<li class="chapter" data-level="20.2" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#internal-and-external-performance-estimates"><i class="fa fa-check"></i><b>20.2</b> Internal and External Performance Estimates</a></li>
<li class="chapter" data-level="20.3" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#basic-syntax-1"><i class="fa fa-check"></i><b>20.3</b> Basic Syntax</a></li>
<li class="chapter" data-level="20.4" data-path="model-training-and-tuning.html"><a href="model-training-and-tuning.html#example"><i class="fa fa-check"></i><b>20.4</b> Example</a></li>
<li class="chapter" data-level="20.5" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#customizing-the-search"><i class="fa fa-check"></i><b>20.5</b> Customizing the Search</a><ul>
<li class="chapter" data-level="20.5.1" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#the-fit-function-3"><i class="fa fa-check"></i><b>20.5.1</b> The <code>fit</code> Function</a></li>
<li class="chapter" data-level="20.5.2" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#the-pred-function-2"><i class="fa fa-check"></i><b>20.5.2</b> The <code>pred</code> Function</a></li>
<li class="chapter" data-level="20.5.3" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#the-fitness_intern-function"><i class="fa fa-check"></i><b>20.5.3</b> The <code>fitness_intern</code> Function</a></li>
<li class="chapter" data-level="20.5.4" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#the-fitness_extern-function"><i class="fa fa-check"></i><b>20.5.4</b> The <code>fitness_extern</code> Function</a></li>
<li class="chapter" data-level="20.5.5" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#the-initial-function"><i class="fa fa-check"></i><b>20.5.5</b> The <code>initial</code> Function</a></li>
<li class="chapter" data-level="20.5.6" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#the-selection-function"><i class="fa fa-check"></i><b>20.5.6</b> The <code>selection</code> Function</a></li>
<li class="chapter" data-level="20.5.7" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#the-crossover-function"><i class="fa fa-check"></i><b>20.5.7</b> The <code>crossover</code> Function</a></li>
<li class="chapter" data-level="20.5.8" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#the-mutation-function"><i class="fa fa-check"></i><b>20.5.8</b> The <code>mutation</code> Function</a></li>
<li class="chapter" data-level="20.5.9" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#the-selectiter-function"><i class="fa fa-check"></i><b>20.5.9</b> The <code>selectIter</code> Function</a></li>
</ul></li>
<li class="chapter" data-level="20.6" data-path="feature-selection-using-genetic-algorithms.html"><a href="feature-selection-using-genetic-algorithms.html#the-example-revisited"><i class="fa fa-check"></i><b>20.6</b> The Example Revisited</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="feature-selection-using-simulated-annealing.html"><a href="feature-selection-using-simulated-annealing.html"><i class="fa fa-check"></i><b>21</b> Feature Selection using Simulated Annealing</a><ul>
<li class="chapter" data-level="21.1" data-path="feature-selection-using-simulated-annealing.html"><a href="feature-selection-using-simulated-annealing.html#simulated-annealing"><i class="fa fa-check"></i><b>21.1</b> Simulated Annealing</a></li>
<li class="chapter" data-level="21.2" data-path="feature-selection-using-simulated-annealing.html"><a href="feature-selection-using-simulated-annealing.html#internal-and-external-performance-estimates-1"><i class="fa fa-check"></i><b>21.2</b> Internal and External Performance Estimates</a></li>
<li class="chapter" data-level="21.3" data-path="feature-selection-using-simulated-annealing.html"><a href="feature-selection-using-simulated-annealing.html#basic-syntax-2"><i class="fa fa-check"></i><b>21.3</b> Basic Syntax</a></li>
<li class="chapter" data-level="21.4" data-path="feature-selection-using-simulated-annealing.html"><a href="feature-selection-using-simulated-annealing.html#example-1"><i class="fa fa-check"></i><b>21.4</b> Example</a></li>
<li class="chapter" data-level="21.5" data-path="feature-selection-using-simulated-annealing.html"><a href="feature-selection-using-simulated-annealing.html#customizing-the-search-1"><i class="fa fa-check"></i><b>21.5</b> Customizing the Search</a><ul>
<li class="chapter" data-level="21.5.1" data-path="feature-selection-using-simulated-annealing.html"><a href="feature-selection-using-simulated-annealing.html#the-fit-function-4"><i class="fa fa-check"></i><b>21.5.1</b> The <code>fit</code> Function</a></li>
<li class="chapter" data-level="21.5.2" data-path="feature-selection-using-simulated-annealing.html"><a href="feature-selection-using-simulated-annealing.html#the-pred-function-3"><i class="fa fa-check"></i><b>21.5.2</b> The <code>pred</code> Function</a></li>
<li class="chapter" data-level="21.5.3" data-path="feature-selection-using-simulated-annealing.html"><a href="feature-selection-using-simulated-annealing.html#the-fitness_intern-function-1"><i class="fa fa-check"></i><b>21.5.3</b> The <code>fitness_intern</code> Function</a></li>
<li class="chapter" data-level="21.5.4" data-path="feature-selection-using-simulated-annealing.html"><a href="feature-selection-using-simulated-annealing.html#the-fitness_extern-function-1"><i class="fa fa-check"></i><b>21.5.4</b> The <code>fitness_extern</code> Function</a></li>
<li class="chapter" data-level="21.5.5" data-path="feature-selection-using-simulated-annealing.html"><a href="feature-selection-using-simulated-annealing.html#the-initial-function-1"><i class="fa fa-check"></i><b>21.5.5</b> The <code>initial</code> Function</a></li>
<li class="chapter" data-level="21.5.6" data-path="feature-selection-using-simulated-annealing.html"><a href="feature-selection-using-simulated-annealing.html#the-perturb-function"><i class="fa fa-check"></i><b>21.5.6</b> The <code>perturb</code> Function</a></li>
<li class="chapter" data-level="21.5.7" data-path="feature-selection-using-simulated-annealing.html"><a href="feature-selection-using-simulated-annealing.html#the-prob-function"><i class="fa fa-check"></i><b>21.5.7</b> The <code>prob</code> Function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="data-sets.html"><a href="data-sets.html"><i class="fa fa-check"></i><b>22</b> Data Sets</a><ul>
<li class="chapter" data-level="22.1" data-path="data-sets.html"><a href="data-sets.html#blood-brain-barrier-data"><i class="fa fa-check"></i><b>22.1</b> Blood-Brain Barrier Data</a></li>
<li class="chapter" data-level="22.2" data-path="data-sets.html"><a href="data-sets.html#cox-2-activity-data"><i class="fa fa-check"></i><b>22.2</b> COX-2 Activity Data</a></li>
<li class="chapter" data-level="22.3" data-path="data-sets.html"><a href="data-sets.html#dhfr-inhibition"><i class="fa fa-check"></i><b>22.3</b> DHFR Inhibition</a></li>
<li class="chapter" data-level="22.4" data-path="data-sets.html"><a href="data-sets.html#tecator-nir-data"><i class="fa fa-check"></i><b>22.4</b> Tecator NIR Data</a></li>
<li class="chapter" data-level="22.5" data-path="data-sets.html"><a href="data-sets.html#fatty-acid-composition-data"><i class="fa fa-check"></i><b>22.5</b> Fatty Acid Composition Data</a></li>
<li class="chapter" data-level="22.6" data-path="data-sets.html"><a href="data-sets.html#german-credit-data"><i class="fa fa-check"></i><b>22.6</b> German Credit Data</a></li>
<li class="chapter" data-level="22.7" data-path="data-sets.html"><a href="data-sets.html#kelly-blue-book"><i class="fa fa-check"></i><b>22.7</b> Kelly Blue Book</a></li>
<li class="chapter" data-level="22.8" data-path="data-sets.html"><a href="data-sets.html#cell-body-segmentation-data"><i class="fa fa-check"></i><b>22.8</b> Cell Body Segmentation Data</a></li>
<li class="chapter" data-level="22.9" data-path="data-sets.html"><a href="data-sets.html#sacramento-house-price-data"><i class="fa fa-check"></i><b>22.9</b> Sacramento House Price Data</a></li>
<li class="chapter" data-level="22.10" data-path="data-sets.html"><a href="data-sets.html#animal-scat-data"><i class="fa fa-check"></i><b>22.10</b> Animal Scat Data</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The <code>caret</code> Package</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="subsampling-for-class-imbalances" class="section level1">
<h1><span class="header-section-number">11</span> Subsampling For Class Imbalances</h1>
<p>Contents</p>
<ul>
<li><a href="subsampling-for-class-imbalances.html#methods">Subsampling Techniques</a></li>
<li><a href="subsampling-for-class-imbalances.html#resampling">Subsampling During Resampling</a></li>
<li><a href="subsampling-for-class-imbalances.html#complications">Complications</a></li>
<li><a href="model-training-and-tuning.html#custom">Using Custom Subsampling Techniques</a></li>
</ul>
<p>In classification problems, a disparity in the frequencies of the observed classes can have a significant negative impact on model fitting. One technique for resolving such a class imbalance is to subsample the training data in a manner that mitigates the issues. Examples of sampling methods for this purpose are:</p>
<ul>
<li><em>down-sampling</em>: randomly subset all the classes in the training set so that their class frequencies match the least prevalent class. For example, suppose that 80% of the training set samples are the first class and the remaining 20% are in the second class. Down-sampling would randomly sample the first class to be the same size as the second class (so that only 40% of the total training set is used to fit the model). <strong>caret</strong> contains a function (<code>downSample</code>) to do this.</li>
<li><em>up-sampling</em>: randomly sample (with replacement) the minority class to be the same size as the majority class. <strong>caret</strong> contains a function (<code>upSample</code>) to do this.</li>
<li><em>hybrid methods</em>: techniques such as <a href="https://scholar.google.com/scholar?hl=en&amp;q=SMOTE&amp;btnG=&amp;as_sdt=1%2C33&amp;as_sdtp=">SMOTE</a> and <a href="https://scholar.google.com/scholar?q=%22Training+and+assessing+classification+rules+with+imbalanced+data%22&amp;btnG=&amp;hl=en&amp;as_sdt=0%2C33">ROSE</a> down-sample the majority class and synthesize new data points in the minority class. There are two packages (<strong>DMwR</strong> and <strong>ROSE</strong>) that implement these procedures.</li>
</ul>
<p>Note that this type of sampling is different from splitting the data into a training and test set. You would never want to artificially balance the test set; its class frequencies should be in-line with what one would see in the wild. Also, the above procedures are independent of resampling methods such as cross-validation and the bootstrap.</p>
<p>In practice, one could take the training set and, before model fitting, sample the data. There are two issues with this approach</p>
<ul>
<li>Firstly, during model tuning the holdout samples generated during resampling are also glanced and may not reflect the class imbalance that future predictions would encounter. This is likely to lead to overly optimistic estimates of performance.</li>
<li>Secondly, the subsampling process will probably induce more model uncertainty. Would the model results differ under a different subsample? As above, the resampling statistics are more likely to make the model appear more effective than it actually is.</li>
</ul>
<p>The alternative is to include the subsampling inside of the usual resampling procedure. This is also advocated for pre-process and featur selection steps too. The two disadvantages are that it might increase computational times and that it might also complicate the analysis in other ways (see the <a href="subsampling-for-class-imbalances.html#complications">section below</a> about the pitfalls).</p>
<div id="methods">

</div>
<div id="subsampling-techniques" class="section level2">
<h2><span class="header-section-number">11.1</span> Subsampling Techniques</h2>
<p>To illustrate these methods, lets simulate some data with a class imbalance using this method. We will simulate a training and test set where each contains 10000 samples and a minority class rate of about 5.9%:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)

<span class="kw">set.seed</span>(<span class="dv">2969</span>)
imbal_train &lt;-<span class="st"> </span><span class="kw">twoClassSim</span>(<span class="dv">10000</span>, <span class="dt">intercept =</span> -<span class="dv">20</span>, <span class="dt">linearVars =</span> <span class="dv">20</span>)
imbal_test  &lt;-<span class="st"> </span><span class="kw">twoClassSim</span>(<span class="dv">10000</span>, <span class="dt">intercept =</span> -<span class="dv">20</span>, <span class="dt">linearVars =</span> <span class="dv">20</span>)
<span class="kw">table</span>(imbal_train$Class)</code></pre></div>
<pre><code>## 
## Class1 Class2 
##   9411    589</code></pre>
<p>Lets create different versions of the training set prior to model tuning:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">9560</span>)
down_train &lt;-<span class="st"> </span><span class="kw">downSample</span>(<span class="dt">x =</span> imbal_train[, -<span class="kw">ncol</span>(imbal_train)],
                         <span class="dt">y =</span> imbal_train$Class)
<span class="kw">table</span>(down_train$Class)   </code></pre></div>
<pre><code>## 
## Class1 Class2 
##    589    589</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">9560</span>)
up_train &lt;-<span class="st"> </span><span class="kw">upSample</span>(<span class="dt">x =</span> imbal_train[, -<span class="kw">ncol</span>(imbal_train)],
                     <span class="dt">y =</span> imbal_train$Class)                         
<span class="kw">table</span>(up_train$Class) </code></pre></div>
<pre><code>## 
## Class1 Class2 
##   9411   9411</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(DMwR)

<span class="kw">set.seed</span>(<span class="dv">9560</span>)
smote_train &lt;-<span class="st"> </span><span class="kw">SMOTE</span>(Class ~<span class="st"> </span>., <span class="dt">data  =</span> imbal_train)                         
<span class="kw">table</span>(smote_train$Class) </code></pre></div>
<pre><code>## 
## Class1 Class2 
##   2356   1767</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ROSE)

<span class="kw">set.seed</span>(<span class="dv">9560</span>)
rose_train &lt;-<span class="st"> </span><span class="kw">ROSE</span>(Class ~<span class="st"> </span>., <span class="dt">data  =</span> imbal_train)$data                         
<span class="kw">table</span>(rose_train$Class) </code></pre></div>
<pre><code>## 
## Class1 Class2 
##   4939   5061</code></pre>
<p>For these data, well use a bagged classification and estimate the area under the ROC curve using five repeats of 10-fold CV.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">repeats =</span> <span class="dv">5</span>,
                     <span class="dt">classProbs =</span> <span class="ot">TRUE</span>,
                     <span class="dt">summaryFunction =</span> twoClassSummary)

<span class="kw">set.seed</span>(<span class="dv">5627</span>)
orig_fit &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> imbal_train, 
                  <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,
                  <span class="dt">nbagg =</span> <span class="dv">50</span>,
                  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
                  <span class="dt">trControl =</span> ctrl)

<span class="kw">set.seed</span>(<span class="dv">5627</span>)
down_outside &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> down_train, 
                      <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,
                      <span class="dt">nbagg =</span> <span class="dv">50</span>,
                      <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
                      <span class="dt">trControl =</span> ctrl)

<span class="kw">set.seed</span>(<span class="dv">5627</span>)
up_outside &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> up_train, 
                    <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,
                    <span class="dt">nbagg =</span> <span class="dv">50</span>,
                    <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
                    <span class="dt">trControl =</span> ctrl)

<span class="kw">set.seed</span>(<span class="dv">5627</span>)
rose_outside &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> rose_train, 
                      <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,
                      <span class="dt">nbagg =</span> <span class="dv">50</span>,
                      <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
                      <span class="dt">trControl =</span> ctrl)


<span class="kw">set.seed</span>(<span class="dv">5627</span>)
smote_outside &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> smote_train, 
                       <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,
                       <span class="dt">nbagg =</span> <span class="dv">50</span>,
                       <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
                       <span class="dt">trControl =</span> ctrl)</code></pre></div>
<p>We will collate the resampling results and create a wrapper to estimate the test set performance:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">outside_models &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">original =</span> orig_fit,
                       <span class="dt">down =</span> down_outside,
                       <span class="dt">up =</span> up_outside,
                       <span class="dt">SMOTE =</span> smote_outside,
                       <span class="dt">ROSE =</span> rose_outside)

outside_resampling &lt;-<span class="st"> </span><span class="kw">resamples</span>(outside_models)

test_roc &lt;-<span class="st"> </span>function(model, data) {
  <span class="kw">library</span>(pROC)
  roc_obj &lt;-<span class="st"> </span><span class="kw">roc</span>(data$Class, 
                 <span class="kw">predict</span>(model, data, <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>)[, <span class="st">&quot;Class1&quot;</span>],
                 <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Class2&quot;</span>, <span class="st">&quot;Class1&quot;</span>))
  <span class="kw">ci</span>(roc_obj)
  }

outside_test &lt;-<span class="st"> </span><span class="kw">lapply</span>(outside_models, test_roc, <span class="dt">data =</span> imbal_test)
outside_test &lt;-<span class="st"> </span><span class="kw">lapply</span>(outside_test, as.vector)
outside_test &lt;-<span class="st"> </span><span class="kw">do.call</span>(<span class="st">&quot;rbind&quot;</span>, outside_test)
<span class="kw">colnames</span>(outside_test) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;lower&quot;</span>, <span class="st">&quot;ROC&quot;</span>, <span class="st">&quot;upper&quot;</span>)
outside_test &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(outside_test)

<span class="kw">summary</span>(outside_resampling, <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>)</code></pre></div>
<pre><code>## 
## Call:
## summary.resamples(object = outside_resampling, metric = &quot;ROC&quot;)
## 
## Models: original, down, up, SMOTE, ROSE 
## Number of resamples: 50 
## 
## ROC 
##            Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&#39;s
## original 0.8935  0.9311 0.9407 0.9410  0.9564 0.9717    0
## down     0.8937  0.9205 0.9369 0.9347  0.9549 0.9684    0
## up       0.9995  1.0000 1.0000 0.9999  1.0000 1.0000    0
## SMOTE    0.9622  0.9762 0.9808 0.9796  0.9840 0.9925    0
## ROSE     0.8764  0.8908 0.8953 0.8956  0.8999 0.9166    0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">outside_test</code></pre></div>
<pre><code>##              lower       ROC     upper
## original 0.9134895 0.9251843 0.9368791
## down     0.9238817 0.9315572 0.9392327
## up       0.9360997 0.9437082 0.9513167
## SMOTE    0.9390808 0.9457264 0.9523720
## ROSE     0.9409081 0.9474742 0.9540403</code></pre>
<p>The training and test set estimates for the area under the ROC curve do not appear to correlate. Based on the resampling results, one would infer that up-sampling is nearly perfect and that ROSE does relatively poorly. The reason that up-sampling appears to perform so well is that the samples in the majority class are replicated and have a large potential to be in both the model building and hold-out sets. In essence, the hold-outs here are not truly independent samples.</p>
<p>In reality, all of the sampling methods do about the same (based on the test set). The statistics for the basic model fit with no sampling are fairly in-line with one another (0.941 via resampling and 0.925 for the test set).</p>
<div id="resampling">

</div>
</div>
<div id="subsampling-during-resampling" class="section level2">
<h2><span class="header-section-number">11.2</span> Subsampling During Resampling</h2>
<p>Recent versions of <strong>caret</strong> allow the user to specify subsampling when using <code>train</code> so that it is conducted inside of resampling. All four methods shown above can be accessed with the basic package using simple syntax. If you want to use your own technique, or want to change some of the parameters for <code>SMOTE</code> or <code>ROSE</code>, the last section below shows how to use custom subsampling.</p>
<p>The way to enable subsampling is to use yet another option in <code>trainControl</code> called <code>sampling</code>. The most basic syntax is to use a character string with the name of the sampling method, either <code>&quot;down&quot;</code>, <code>&quot;up&quot;</code>, <code>&quot;smote&quot;</code>, or <code>&quot;rose&quot;</code>. Note that you will need to have the <strong>DMwR</strong> and <strong>ROSE</strong> packages installed to use SMOTE and ROSE, respectively.</p>
<p>One complication is related to pre-processing. Should the subsampling occur before or after the pre-processing? For example, if you down-sample the data and using PCA for signal extraction, should the loadings be estimated from the entire training set? The estimate is potentially better since the entire training set is being used but the subsample may happen to capture a small potion of the PCA space. There isnt any obvious answer.</p>
<p>The default behavior is to subsample the data prior to pre-processing. This can be easily changed and an example is given below.</p>
<p>Now lets re-run our bagged tree models while sampling inside of cross-validation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">repeats =</span> <span class="dv">5</span>,
                     <span class="dt">classProbs =</span> <span class="ot">TRUE</span>,
                     <span class="dt">summaryFunction =</span> twoClassSummary,
                     ## new option here:
                     <span class="dt">sampling =</span> <span class="st">&quot;down&quot;</span>)

<span class="kw">set.seed</span>(<span class="dv">5627</span>)
down_inside &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> imbal_train,
                     <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,
                     <span class="dt">nbagg =</span> <span class="dv">50</span>,
                     <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
                     <span class="dt">trControl =</span> ctrl)

## now just change that option
ctrl$sampling &lt;-<span class="st"> &quot;up&quot;</span>

<span class="kw">set.seed</span>(<span class="dv">5627</span>)
up_inside &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> imbal_train,
                   <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,
                   <span class="dt">nbagg =</span> <span class="dv">50</span>,
                   <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
                   <span class="dt">trControl =</span> ctrl)

ctrl$sampling &lt;-<span class="st"> &quot;rose&quot;</span>

<span class="kw">set.seed</span>(<span class="dv">5627</span>)
rose_inside &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> imbal_train,
                     <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,
                     <span class="dt">nbagg =</span> <span class="dv">50</span>,
                     <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
                     <span class="dt">trControl =</span> ctrl)

ctrl$sampling &lt;-<span class="st"> &quot;smote&quot;</span>

<span class="kw">set.seed</span>(<span class="dv">5627</span>)
smote_inside &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> imbal_train,
                      <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,
                      <span class="dt">nbagg =</span> <span class="dv">50</span>,
                      <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
                      <span class="dt">trControl =</span> ctrl)</code></pre></div>
<p>Here are the resampling and test set results:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">inside_models &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">original =</span> orig_fit,
                      <span class="dt">down =</span> down_inside,
                      <span class="dt">up =</span> up_inside,
                      <span class="dt">SMOTE =</span> smote_inside,
                      <span class="dt">ROSE =</span> rose_inside)

inside_resampling &lt;-<span class="st"> </span><span class="kw">resamples</span>(inside_models)

inside_test &lt;-<span class="st"> </span><span class="kw">lapply</span>(inside_models, test_roc, <span class="dt">data =</span> imbal_test)
inside_test &lt;-<span class="st"> </span><span class="kw">lapply</span>(inside_test, as.vector)
inside_test &lt;-<span class="st"> </span><span class="kw">do.call</span>(<span class="st">&quot;rbind&quot;</span>, inside_test)
<span class="kw">colnames</span>(inside_test) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;lower&quot;</span>, <span class="st">&quot;ROC&quot;</span>, <span class="st">&quot;upper&quot;</span>)
inside_test &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(inside_test)

<span class="kw">summary</span>(inside_resampling, <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>)</code></pre></div>
<pre><code>## 
## Call:
## summary.resamples(object = inside_resampling, metric = &quot;ROC&quot;)
## 
## Models: original, down, up, SMOTE, ROSE 
## Number of resamples: 50 
## 
## ROC 
##            Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&#39;s
## original 0.8935  0.9311 0.9407 0.9410  0.9564 0.9717    0
## down     0.8902  0.9348 0.9445 0.9421  0.9507 0.9665    0
## up       0.8928  0.9211 0.9374 0.9352  0.9499 0.9637    0
## SMOTE    0.9299  0.9458 0.9528 0.9527  0.9609 0.9761    0
## ROSE     0.9189  0.9440 0.9529 0.9517  0.9597 0.9741    0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">inside_test</code></pre></div>
<pre><code>##              lower       ROC     upper
## original 0.9134895 0.9251843 0.9368791
## down     0.9234409 0.9308037 0.9381665
## up       0.9241506 0.9340749 0.9439992
## SMOTE    0.9455682 0.9512705 0.9569727
## ROSE     0.9413039 0.9482492 0.9551946</code></pre>
<p>The figure below shows the difference in the area under the ROC curve and the test set results for the approaches shown here. Repeating the subsampling procedures for every resample produces results that are more consistent with the test set.</p>
<p><img src="_main_files/figure-html/samp_insode_plot-1.png" width="672" /></p>
</div>
<div id="complications" class="section level2">
<h2><span class="header-section-number">11.3</span> Complications</h2>
<p>The user should be aware that there are a few things that can happening when subsampling that can cause issues in their code. As previously mentioned, when sampling occurs in relation to pre-processing is one such issue. Others are:</p>
<ul>
<li>Sparsely represented categories in factor variables may turn into zero-variance predictors or may be completely sampled out of the model.</li>
<li>The underlying functions that do the sampling (e.g. <code>SMOTE</code>, <code>downSample</code>, etc) operate in very different ways and this can affect your results. For example, <code>SMOTE</code> and <code>ROSE</code> will convert your predictor input argument into a data frame (even if you start with a matrix).</li>
<li>Currently, sample weights are not supported with sub-sampling.</li>
<li>If you use <code>tuneLength</code> to specify the search grid, understand that the data that is used to determine the grid has not been sampled. In most cases, this will not matter but if the grid creation process is affected by the sample size, you may end up using a sub-optimal tuning grid.</li>
<li>For some models that require more samples than parameters, a reduction in the sample size may prevent you from being able to fit the model.</li>
</ul>
<div id="custom">

</div>
</div>
<div id="using-custom-subsampling-techniques" class="section level2">
<h2><span class="header-section-number">11.4</span> Using Custom Subsampling Techniques</h2>
<p>Users have the ability to create their own type of subsampling procedure. To do this, alternative syntax is used with the <code>sampling</code> argument of the <code>trainControl</code>. Previously, we used a simple string as the value of this argument. Another way to specify the argument is to use a list with three (named) elements:</p>
<ul>
<li>The <code>name</code> value is a character string used when the <code>train</code> object is printed. It can be any string.</li>
<li>The <code>func</code> element is a function that does the subsampling. It should have arguments called <code>x</code> and <code>y</code> that will contain the predictors and outcome data, respectively. The function should return a list with elements of the same name.</li>
<li>The <code>first</code> element is a single logical value that indicates whether the subsampling should occur first relative to pre-process. A value of <code>FALSE</code> means that the subsampling function will receive the sampled versions of <code>x</code> and <code>y</code>.</li>
</ul>
<p>For example, here is what the list version of the <code>sampling</code> argument looks like when simple down-sampling is used:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">down_inside$control$sampling</code></pre></div>
<pre><code>## $name
## [1] &quot;down&quot;
## 
## $func
## function (x, y) 
## downSample(x, y, list = TRUE)
## 
## $first
## [1] TRUE</code></pre>
<p>As another example, suppose we want to use SMOTE but use 10 nearest neighbors instead of the default of 5. To do this, we can create a simple wrapper around the <code>SMOTE</code> function and call this instead:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smotest &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">name =</span> <span class="st">&quot;SMOTE with more neighbors!&quot;</span>,
                <span class="dt">func =</span> function (x, y) {
                  <span class="kw">library</span>(DMwR)
                  dat &lt;-<span class="st"> </span>if (<span class="kw">is.data.frame</span>(x)) x else <span class="kw">as.data.frame</span>(x)
                  dat$.y &lt;-<span class="st"> </span>y
                  dat &lt;-<span class="st"> </span><span class="kw">SMOTE</span>(.y ~<span class="st"> </span>., <span class="dt">data =</span> dat, <span class="dt">k =</span> <span class="dv">10</span>)
                  <span class="kw">list</span>(<span class="dt">x =</span> dat[, !<span class="kw">grepl</span>(<span class="st">&quot;.y&quot;</span>, <span class="kw">colnames</span>(dat), <span class="dt">fixed =</span> <span class="ot">TRUE</span>)], 
                       <span class="dt">y =</span> dat$.y)
                  },
                <span class="dt">first =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>The control object would then be:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">repeats =</span> <span class="dv">5</span>,
                     <span class="dt">classProbs =</span> <span class="ot">TRUE</span>,
                     <span class="dt">summaryFunction =</span> twoClassSummary,
                     <span class="dt">sampling =</span> smotest)</code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="random-hyperparameter-search.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="using-your-own-model-in-train.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
